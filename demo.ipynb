{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558b1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "699ed640",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL='openai/gpt-5-nano'\n",
    "API_KEY=os.getenv('OPENAI_API_KEY')\n",
    "LOCAL=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec81c11f",
   "metadata": {},
   "source": [
    "## Learn DSPy fundamentals through conversation!\n",
    "\n",
    "### This notebook demonstrates:\n",
    "\n",
    "* DSPy Signatures (conversation interface)\n",
    "* DSPy ReAct (tool usage & agent reasoning)\n",
    "* Multi-Agent Orchestration (intelligent routing)\n",
    "* DSPy History (context management)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e533cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Configure DSPy with your LLM\n",
    "if not LOCAL:\n",
    "    MODEL='openai/gpt-5-nano'\n",
    "    LLM = dspy.LM(model=MODEL, temperature=1.0, max_tokens=16000, api_key=API_KEY)\n",
    "else:\n",
    "    MODEL='lm_studio/qwen/qwen3-coder-30b'\n",
    "    LLM = dspy.LM(model=MODEL, api_base=\"http://192.168.0.49:1234/v1/\", api_key=\"local\")\n",
    "\n",
    "dspy.configure(lm=LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1a8c497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Hello there! It's nice to meet you! ðŸŒŸ\\n\\nI'm Qwen, a large language model developed by Tongyi Lab. I can help with various tasks like answering questions, creating text, logical reasoning, programming, and more. I'm designed to be a versatile AI assistant that can communicate in multiple languages and provide useful information and support.\\n\\nFeel free to ask me anything you'd like to know or any questions you might have - I'm here to help!\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM(\"Hi there, can you send a greeting and a quick introduction of yourself!?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33cbb7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_studio/qwen/qwen3-coder-30b: The Eiffel Tower was built between 1887 and 1889, with completion in March 1889.\n",
      "The Eiffel Tower was built between 1887 and 1889. It was constructed as the entrance arch for the 1889 World's Fair (Exposition Universelle) held in Paris to celebrate the 100th anniversary of the French Revolution. The tower was designed by engineer Gustave Eiffel, and construction began in January 1887, with the structure being completed in March 1889.\n"
     ]
    }
   ],
   "source": [
    "qa = dspy.ChainOfThought('question -> answer')\n",
    "response = qa(question=\"What Year was The Eiffel Tower built?\")\n",
    "print(f'{MODEL}:', response.answer)\n",
    "print(response.reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74694167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 items in the history\n",
      "\n",
      "dict_keys(['prompt', 'messages', 'kwargs', 'response', 'outputs', 'usage', 'cost', 'timestamp', 'uuid', 'model', 'response_model', 'model_type']) \n",
      "\n",
      "prompt: Hi there, can you send a greeting and a quick introduction of yourself!?\n",
      "messages: None\n",
      "kwargs: {}\n",
      "response: ModelResponse(id='chatcmpl-01gebhgi4nfh11hvjtk4l2fg', created=1760949530, model='lm_studio/qwen/qwen3-coder-30b', object='chat.completion', system_fingerprint='qwen/qwen3-coder-30b', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Hello there! It's nice to meet you! ðŸŒŸ\\n\\nI'm Qwen, a large language model developed by Tongyi Lab. I can help with various tasks like answering questions, creating text, logical reasoning, programming, and more. I'm designed to be a versatile AI assistant that can communicate in multiple languages and provide useful information and support.\\n\\nFeel free to ask me anything you'd like to know or any questions you might have - I'm here to help!\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}), provider_specific_fields={})], usage=Usage(completion_tokens=95, prompt_tokens=23, total_tokens=118, completion_tokens_details=None, prompt_tokens_details=None), service_tier=None, stats={})\n",
      "outputs: [\"Hello there! It's nice to meet you! ðŸŒŸ\\n\\nI'm Qwen, a large language model developed by Tongyi Lab. I can help with various tasks like answering questions, creating text, logical reasoning, programming, and more. I'm designed to be a versatile AI assistant that can communicate in multiple languages and provide useful information and support.\\n\\nFeel free to ask me anything you'd like to know or any questions you might have - I'm here to help!\"]\n",
      "usage: {'completion_tokens': 95, 'prompt_tokens': 23, 'total_tokens': 118, 'completion_tokens_details': None, 'prompt_tokens_details': None}\n",
      "cost: None\n",
      "timestamp: 2025-10-20T09:38:51.809977\n",
      "uuid: fe9acbbe-9105-4807-a207-3020408e737b\n",
      "model: lm_studio/qwen/qwen3-coder-30b\n",
      "response_model: lm_studio/qwen/qwen3-coder-30b\n",
      "model_type: chat\n",
      "\n",
      "\n",
      "prompt: None\n",
      "messages: [{'role': 'system', 'content': 'Your input fields are:\\n1. `question` (str):\\nYour output fields are:\\n1. `reasoning` (str): \\n2. `answer` (str):\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\n\\n[[ ## question ## ]]\\n{question}\\n\\n[[ ## reasoning ## ]]\\n{reasoning}\\n\\n[[ ## answer ## ]]\\n{answer}\\n\\n[[ ## completed ## ]]\\nIn adhering to this structure, your objective is: \\n        Given the fields `question`, produce the fields `answer`.'}, {'role': 'user', 'content': '[[ ## question ## ]]\\nWhat Year was The Eiffel Tower built?\\n\\nRespond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.'}]\n",
      "kwargs: {}\n",
      "response: ModelResponse(id='chatcmpl-2lgqfq7iw98hkdrgcaquj', created=1760949531, model='lm_studio/qwen/qwen3-coder-30b', object='chat.completion', system_fingerprint='qwen/qwen3-coder-30b', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"[[ ## reasoning ## ]]\\nThe Eiffel Tower was built between 1887 and 1889. It was constructed as the entrance arch for the 1889 World's Fair (Exposition Universelle) held in Paris to celebrate the 100th anniversary of the French Revolution. The tower was designed by engineer Gustave Eiffel, and construction began in January 1887, with the structure being completed in March 1889.\\n\\n[[ ## answer ## ]]\\nThe Eiffel Tower was built between 1887 and 1889, with completion in March 1889.\\n\\n[[ ## completed ## ]]\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}), provider_specific_fields={})], usage=Usage(completion_tokens=142, prompt_tokens=176, total_tokens=318, completion_tokens_details=None, prompt_tokens_details=None), service_tier=None, stats={})\n",
      "outputs: [\"[[ ## reasoning ## ]]\\nThe Eiffel Tower was built between 1887 and 1889. It was constructed as the entrance arch for the 1889 World's Fair (Exposition Universelle) held in Paris to celebrate the 100th anniversary of the French Revolution. The tower was designed by engineer Gustave Eiffel, and construction began in January 1887, with the structure being completed in March 1889.\\n\\n[[ ## answer ## ]]\\nThe Eiffel Tower was built between 1887 and 1889, with completion in March 1889.\\n\\n[[ ## completed ## ]]\"]\n",
      "usage: {'completion_tokens': 142, 'prompt_tokens': 176, 'total_tokens': 318, 'completion_tokens_details': None, 'prompt_tokens_details': None}\n",
      "cost: None\n",
      "timestamp: 2025-10-20T09:38:54.578514\n",
      "uuid: 84168770-0994-4f9a-a99a-cbc0be586184\n",
      "model: lm_studio/qwen/qwen3-coder-30b\n",
      "response_model: lm_studio/qwen/qwen3-coder-30b\n",
      "model_type: chat\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(LLM.history)} items in the history\\n')  \n",
    "\n",
    "print(LLM.history[-1].keys(),'\\n')  # access the last call to the LM, with all metadata\n",
    "\n",
    "for item in LLM.history:\n",
    "    for key, value in item.items():\n",
    "        print(f'{key}: {value}')\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661d152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are ugly. | Toxic?: True\n",
      "What a nice guy! | Toxic?: False\n",
      "I hate you so much | Toxic?: True\n",
      "Great job on that project! | Toxic?: False\n",
      "You're worthless | Toxic?: True\n",
      "Thank you for your help | Toxic?: False\n",
      "Stop being so stupid | Toxic?: True\n",
      "You did an amazing work | Toxic?: False\n",
      "I can't stand you | Toxic?: True\n",
      "I appreciate your effort | Toxic?: False\n"
     ]
    }
   ],
   "source": [
    "toxicity = dspy.Predict(\n",
    "    dspy.Signature(\n",
    "        \"comment:str -> toxic: bool\",\n",
    "        instructions=\"Mark as 'toxic' if the comment includes insults, harassment, or sarcastic derogatory remarks.\",\n",
    "    )\n",
    ")\n",
    "\n",
    "comments = [\n",
    "    \"you are ugly.\",\n",
    "    \"What a nice guy!\",\n",
    "    \"I hate you so much\",\n",
    "    \"Great job on that project!\",\n",
    "    \"You're worthless\",\n",
    "    \"Thank you for your help\",\n",
    "    \"Stop being so stupid\",\n",
    "    \"You did an amazing work\",\n",
    "    \"I can't stand you\",\n",
    "    \"I appreciate your effort\"\n",
    "]\n",
    "\n",
    "for comment in comments:\n",
    "    print(comment,'| Toxic?:', toxicity(comment=comment).toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e767029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm so frustrated with this terrible service and endless waiting times.\n",
      "2 out of 10\n",
      "\n",
      "The weather is disappointing, but at least we have indoor activities.\n",
      "4 out of 10\n",
      "\n",
      "The meeting was scheduled for 3 PM, which is standard for our team.\n",
      "7 out of 10\n",
      "\n",
      "I'm feeling better after getting some rest and fresh air.\n",
      "7 out of 10\n",
      "\n",
      "What an amazing day filled with wonderful surprises and joyful moments!\n",
      "9 out of 10\n",
      "\n",
      "This product is absolutely horrible and waste of money.\n",
      "2 out of 10\n",
      "\n",
      "The customer support was very helpful and solved my issue quickly.\n",
      "8 out of 10\n",
      "\n",
      "I hate this movie, it's boring and poorly acted.\n",
      "2 out of 10\n",
      "\n",
      "The restaurant had excellent food and great atmosphere.\n",
      "9 out of 10\n",
      "\n",
      "This software is confusing and difficult to use.\n",
      "3 out of 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"I'm so frustrated with this terrible service and endless waiting times.\",\n",
    "    \"The weather is disappointing, but at least we have indoor activities.\",\n",
    "    \"The meeting was scheduled for 3 PM, which is standard for our team.\",\n",
    "    \"I'm feeling better after getting some rest and fresh air.\",\n",
    "    \"What an amazing day filled with wonderful surprises and joyful moments!\",\n",
    "    \"This product is absolutely horrible and waste of money.\",\n",
    "    \"The customer support was very helpful and solved my issue quickly.\",\n",
    "    \"I hate this movie, it's boring and poorly acted.\",\n",
    "    \"The restaurant had excellent food and great atmosphere.\",\n",
    "    \"This software is confusing and difficult to use.\"\n",
    "]\n",
    "\n",
    "sentiment_analysis = dspy.Predict(\n",
    "    dspy.Signature(\n",
    "        'sentence -> sentiment: int',\n",
    "        instructions= \"Give me a value from 1-10 indicating the sentiment, 1 being very negative and 10 being overwhelmingly positive\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    print(f'{sentiment_analysis(sentence=sentence).sentiment} out of 10\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57fe9e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length (characters): 2159\n",
      "summarised length (characters): 565\n",
      "Marcus, a street vendor who has been selling coffee and bagels on the same corner for fifteen years since his wife's passing, experiences a meaningful moment of human connection during a rainy night. After selling his last cup to an elderly woman, he offers coffee to a young man huddled under an overpass, recognizing shared struggle and providing warmth in the cold urban environment. The story portrays Marcus as more than just a vendorâ€”he becomes a beacon of humanity in a city that often overlooks those trying to keep it together, one cup of coffee at a time.\n"
     ]
    }
   ],
   "source": [
    "document = \"\"\"The rain hammered against the cracked pavement as Marcus clutched his worn canvas bag, his weathered hands trembling slightly from the cold. He had been selling hot coffee and bagels on this corner for fifteen years, ever since his wife passed away, but tonight felt differentâ€”perhaps because the steady stream of commuters had thinned to just a few desperate souls seeking warmth. His small cart, tucked between the towering glass buildings, cast a faint glow through the misty darkness, and he watched as an elderly woman with a umbrella approached, her face illuminated by the yellow light. She purchased his last cup of coffee, and as she walked away, Marcus smiled, knowing that even in the rain, someone was still finding comfort in his simple offering.\n",
    "The city's endless rhythm continued around him, but for this moment, he felt like he was making a difference. The rain had been falling for hours now, turning the streets into rivers of gray water that reflected the neon signs of the nearby restaurants and stores. His cart, though modest, had become a familiar presence on this corner, a small oasis in the concrete jungle where people could pause, warm themselves, and perhaps find a moment of human connection in their hurried lives.\n",
    "As he wiped the condensation from his coffee cup, Marcus noticed a young man huddled under an overpass nearby, his jacket soaked through. The boy's eyes met Marcus's, and for a brief second, there was something in that lookâ€”hope, maybe desperation, or simply recognition of shared struggle. Marcus reached into his bag and pulled out another cup of coffee, offering it to the boy without hesitation. The young man accepted it with a quiet \"thank you,\" and Marcus felt that familiar warmth spreading through his chest, the kind that only comes from knowing you've made someone's night just a little bit better.\n",
    "The rain continued its relentless assault, but Marcus was no longer alone in the darkness. He had become more than just a vendor; he had become a small beacon of humanity in a city that often forgot to look up and notice the people who were trying to keep it all together, one cup of coffee at a time.\n",
    "\"\"\"\n",
    "print(f'original length (characters): {len(document)}')\n",
    "\n",
    "summarize = dspy.ChainOfThought('document -> summary')\n",
    "response = summarize(document=document)\n",
    "print(f'summarised length (characters): {len(response.summary)}')\n",
    "\n",
    "print(response.summary)\n",
    "# print(\"Reasoning:\", response.reasoning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
